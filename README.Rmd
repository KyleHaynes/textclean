---
title: "textclean"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  md_document:
    toc: true      
---

```{r, echo=FALSE}
desc <- suppressWarnings(readLines("DESCRIPTION"))
regex <- "(^Version:\\s+)(\\d+\\.\\d+\\.\\d+)"
loc <- grep(regex, desc)
ver <- gsub(regex, "\\2", desc[loc])
verbadge <- sprintf('<a href="https://img.shields.io/badge/Version-%s-orange.svg"><img src="https://img.shields.io/badge/Version-%s-orange.svg" alt="Version"/></a></p>', ver, ver)
````

[![Project Status: Active - The project has reached a stable, usable
state and is being actively
developed.](http://www.repostatus.org/badges/0.1.0/active.svg)](http://www.repostatus.org/#active)
[![Build Status](https://travis-ci.org/trinker/textclean.svg?branch=master)](https://travis-ci.org/trinker/textclean)
[![Coverage Status](https://coveralls.io/repos/trinker/textclean/badge.svg?branch=master)](https://coveralls.io/r/trinker/textclean?branch=master)
`r verbadge`

<img src="inst/textclean_logo/r_textclean2.png" width="200" alt="textclean Logo">

**textclean** is a collection of tools to clean and process text.  Many of these tools have been taken from the **qdap** package and revamped to be more intuitive, better named, and faster.

# Functions

The main functions, task category, & descriptions are summarized in the table below:


| Function                  | Task        | Description                           | 
|---------------------------|-------------|---------------------------------------| 
| `mgsub`                   | subbing     | Multiple `gsub`                       |
| `sub_holder`              | subbing     | Hold a value prior to a `strip`       |
| `strip`                   | deletion    | Remove all non word characters        |
| `filter_empty_row`        | filter rows | Remove empty rows                     |
| `filter_row`              | filter rows | Remove rows matching a regex          |
| `filter_NA`               | filter rows | Remove `NA` text rows                 |
| `replace_contractions`    | replacement | Replace contractions with both words  |
| `replace_incomplete`      | replacement | Replace incomplete sentence end-marks  |
| `replace_non_ascii`       | replacement | Replace non-ascii with equivalent or remove   |
| `replace_number`          | replacement | Replace common numbers                |
| `replace_ordinal`         | replacement | Replace common ordinal number form    |
| `replace_symbol`          | replacement | Replace common symbols                |
| `replace_white`           | replacement | Replace regex white space characters  |
| `add_comma_space`         | repalcement | Replace non-space after comma         |
| `check_text`              | check       | Text report of potential issues       | 
| `has_endmark`             | check       | Check if an element has an end-mark   | 

# Installation

To download the development version of **textclean**:

Download the [zip ball](https://github.com/trinker/textclean/zipball/master) or [tar ball](https://github.com/trinker/textclean/tarball/master), decompress and run `R CMD INSTALL` on it, or use the **pacman** package to install the development version:

```r
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh(
    "trinker/lexicon",    
    "trinker/textclean"
)
```

# Contact

You are welcome to:    
- submit suggestions and bug-reports at: <https://github.com/trinker/textclean/issues>    
- send a pull request on: <https://github.com/trinker/textclean/>    
- compose a friendly e-mail to: <tyler.rinker@gmail.com>    


# Demonstration

## Load the Packages/Data

```{r, message=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr)
pacman::p_load_gh("trinker/textclean", "trinker/textshape", "trinker/lexicon")
```

## Check Text

One of the most useful tools in **textclean** is `check_text` which scans text variables and reports potential problems.  Not all potential problems are definite problems for analysis but the report provides an overview of what may need further preparation.  The report also provides suggested functions for the reported problems.  The report provides information on the following:

1. **non_character** - Text that is `factor`.
2. **missing_ending_punctuation** - Text with no endmark at the end of the string.
3. **empty** - Text that contains an empty element (i.e., `""`).
4. **double_punctuation** - Text that contains two punctuation marks in the same string.
5. **non_space_after_comma** - Text that contains commas with no space after them.
6. **no_alpha** - Text that contains string elements with no alphabetic characters.
7. **non_ascii** - Text that contains non-ASCII characters.
8. **missing_value** - Text that contains missing values (i.e., `NA`).
9. **containing_escaped** - Text that contains escaped (see `?Quotes`).
10. **containing_digits** - Text that contains digits.
11. **indicating_incomplete** - Text that contains endmarks that are indicative of incomplete/trailing sentences (e.g., `...`).
12. **potentially_misspelled** - Text that contains potentially misspelled words.

Here is an example:

```{r}
x <- as.factor(c("i like", "i want. thet them ther .", "I am ! that|", "", NA, 
    "they,were there", ".", "   ", "?", "3;", "I like goud eggs!", 
    "i 4like...", "\\tgreat",  "She said \"yes\""))
check_text(x)
```

And if all is well the user should be greeted by a cow:

```{r}
y <- c("A valid sentence.", "yet another!")
check_text(y)
```


## Row Filtering

It is useful to filter/remove empty rows or unwanted rows (for example the researcher dialogue from a transcript).  The `filter_empty_row` & `filter_row` do empty row do just this.  First I'll demo the removal of empty rows.


```{r}
## create a data set wit empty rows
(dat <- rbind.data.frame(DATA[, c(1, 4)], matrix(rep(" ", 4), 
    ncol =2, dimnames=list(12:13, colnames(DATA)[c(1, 4)]))))

filter_empty_row(dat)
```

Next we filter out rows.  The `filter_row` function takes a data set, a column (named or numeric position) and regex terms to search for.  The `terms` argument takes regex(es) allowing for partial matching.  `terms` is case sensitive  but can be changed via the `ignore.case` argument.

```{r}
filter_row(dataframe = DATA, column = "person", terms = c("sam", "greg"))
filter_row(DATA, 1, c("sam", "greg"))
filter_row(DATA, "state", c("Comp"))
filter_row(DATA, "state", c("I "))
filter_row(DATA, "state", c("you"), ignore.case = TRUE)
```

## Stripping

Often it is useful to remove all non relevant symbols and case from a text (letters, spaces, and apostrophes are retained).  The `strip` function accomplishes this.  The `char.keep` argument allows the user to retain characters.


```{r}
strip(DATA$state)
strip(DATA$state, apostrophe.remove = TRUE)
strip(DATA$state, char.keep = c("?", "."))
```


## Subbing

### Multiple Subs

`gsub` is a great tool but often the user wants to replace a vector of elements with another vector.  `mgsub` allows for a vector of patterns and replacements.  Note that the first argument of `mgsub` is the data, not the `pattern` as is standard with base R's `gsub`.  This allows `mgsub` to be used in a **magrittr** pipeline more easily.  Also note that by default `fixed = TRUE`.  This means the search `pattern` is not a regex per-se.  This makes the replacement much faster when a regex search is not needed.  `mgsub` also reorders the patterns to ensure patterns contained within patterns don't over write the longer pattern.  For example if the pattern `c('i', 'it')` is given the longer `'it'` is replaced first (though `order.pattern = FALSE` can be used to negate this feature).

```{r}
mgsub(DATA$state, c("it's", "I'm"), c("<<it is>>", "<<I am>>"))
mgsub(DATA$state, "[[:punct:]]", "<<PUNCT>>", fixed = FALSE)
mgsub(DATA$state, c("i", "it"), c("<<I>>", "[[IT]]"))
mgsub(DATA$state, c("i", "it"), c("<<I>>", "[[IT]]"), order.pattern = FALSE)
```

### Stashing Character Pre-Sub

There are times the user may want to stash a set of characters before subbing out and then return the stashed characters.  An example of this is when a researcher wants to remove punctuation but not emoticons.  The `subholder` function provides tooling to stash the emoticons, allow a punctuation stripping, and then return the emoticons.  First I'll create some fake text data with emoticons, then stash the emoticons (using a unique text key to hold their place), then I'll strip out the punctuation, and last put the stashed emoticons back.


```{r}
(fake_dat <- paste(key_emoticons[1:11, 1, with=FALSE][[1]], DATA$state))
(m <- sub_holder(fake_dat, key_emoticons[[1]]))
(m_stripped <-strip(m$output))
m$unhold(m_stripped)
```


## Replacement

**textclean** contains tools to replace substrings within text with other substrings that may be easier to analyze.  This section outlines the uses of these tools.  

### Contractions

Some analysis techniques require contractions to be replaced with their multi-word forms (e.g., "I'll" -> "I will").  `replace_contrction` provides this functionality.

```{r}
x <- c("Mr. Jones isn't going.",  
    "Check it out what's going on.",
    "He's here but didn't go.",
    "the robot at t.s. wasn't nice", 
    "he'd like it if i'd go away")

replace_contraction(x)
```

### Incomplete Sentences

Sometimes an incomplete sentence is denoted with multiple end marks or no punctuation at all.  `replace_incomplete` standardizes these sentences with a pipe (`|`) endmark (or one of the users choice).

```{r}
x <- c("the...",  "I.?", "you.", "threw..", "we?")
replace_incomplete(x)
replace_incomplete(x, '...')
```

### Non-ASCII Characters

R can choke on non-ASCII characters.  They can be re-encoded but the new encoding may lack iterpretablity (e.g., &cent; may be converted to `\xA2` which is not easily understood or likely to be matched in a hash look up).  `replace_non_ascii` attempts to replace common non-ASCII characters with a text representation (e.g., &cent; becomes "cent")  Non recognized non-ASCII characters are simply removed (unless `remove.nonconverted = FALSE`).


```{r}
x <- c(
    "Hello World", "6 Ekstr\xf8m", "J\xf6reskog", "bi\xdfchen Z\xfcrcher",
    'This is a \xA9 but not a \xAE', '6 \xF7 2 = 3', 'fractions \xBC, \xBD, \xBE',
    'cows go \xB5', '30\xA2'
)
Encoding(x) <- "latin1"
x

replace_non_ascii(x)
replace_non_ascii(x, remove.nonconverted = FALSE)
```

### Numbers

Some analysis requires numbers to be converted to text form.  `replace_number` attempts to perform this task.  `replace_number` handles comma separated numbers as well.

```{r}
x <- c("I like 346,457 ice cream cones.", "They are 99 percent good")
y <- c("I like 346457 ice cream cones.", "They are 99 percent good")
replace_number(x)
replace_number(y)
replace_number(x, num.paste = TRUE)
replace_number(x, remove=TRUE)
```

### Ordinal Numbers

Afain, some analysis requires numbers, including ordinal numbers, to be converted to text form.  `replace_ordinal` attempts to perform this task for ordinal number 1-100 (i.e., 1st - 100th).  


```{r}
x <- c(
    "I like the 1st one not the 22nd one.", 
    "For the 100th time stop those 3 things!",
    "I like the 3rd 1 not the 12th 1."
)
replace_ordinal(x)
replace_ordinal(x, TRUE)
replace_ordinal(x, remove = TRUE)
replace_number(replace_ordinal(x))
```


### Symbols

Text often contains short-hand representations of words/phrases.  These symbols may contain analyzable information but in the symbolic form they cannot be parsed.  The `replace_symbol` function attempts to replace the symbols `c("$", "%", "#", "@", "& "w/")` with their word equivalents.

```{r}
x <- c("I am @ Jon's & Jim's w/ Marry", 
    "I owe $41 for food", 
    "two is 10% of a #"
)
replace_symbol(x)
```

### White Space

Regex white space characters (e.g., `\n`, `\t`, `\r`) matched by `\s` may impede analysis.  These can be replaced with a single space `" "` via the `replace_white` function.

```{r}
x <- "I go \r
    to   the \tnext line"
x
cat(x)
replace_white(x)
```







